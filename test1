import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

from sklearn.linear_model import RidgeCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

base_path = "C:/Users/Astevenson/Downloads/house-prices-advanced-regression-techniques"
train_path = os.path.join(base_path, "train.csv")
test_path = os.path.join(base_path, "test.csv")
submission_path = os.path.join(base_path, "submission_ridge.csv")

train = pd.read_csv(train_path)
test = pd.read_csv(test_path)
test_ids = test["Id"]

train["SalePrice"] = np.log1p(train["SalePrice"])
all_data = pd.concat([train.drop("SalePrice", axis=1), test], axis=0)

all_data["TotalSF"] = all_data["TotalBsmtSF"] + all_data["1stFlrSF"] + all_data["2ndFlrSF"]
all_data["Age"] = all_data["YrSold"] - all_data["YearBuilt"]
all_data["RemodAge"] = all_data["YrSold"] - all_data["YearRemodAdd"]

num_cols = all_data.select_dtypes(include=[np.number]).columns
cat_cols = all_data.select_dtypes(include=["object"]).columns
all_data[num_cols] = all_data[num_cols].fillna(all_data[num_cols].median())
all_data[cat_cols] = all_data[cat_cols].fillna("Missing")

all_data = pd.get_dummies(all_data, columns=cat_cols, drop_first=True)

X_train = all_data[:train.shape[0]]
X_test = all_data[train.shape[0]:]
y_train = train["SalePrice"]

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

alphas = [0.01, 0.1, 1.0, 10.0, 100.0]
ridge = RidgeCV(alphas=alphas, scoring="neg_mean_squared_error", cv=10)
ridge.fit(X_train_scaled, y_train)

train_preds = ridge.predict(X_train_scaled)
rmse = np.sqrt(mean_squared_error(y_train, train_preds))

print("Train RMSE (log):", round(rmse, 4))
print("Best Alpha:", ridge.alpha_)

test_preds = np.expm1(ridge.predict(X_test_scaled))
submission = pd.DataFrame({"Id": test_ids, "SalePrice": test_preds})
submission.to_csv(submission_path, index=False)
print("Submission saved to:", submission_path)

coef_series = pd.Series(ridge.coef_, index=X_train.columns)
top_features = coef_series.sort_values(key=np.abs, ascending=False).head(15)

plt.figure(figsize=(10, 6))
sns.barplot(x=top_features.values, y=top_features.index)
plt.title("Top 15 Most Influential Features on SalePrice")
plt.xlabel("Model Weight (Coefficient)")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

residuals = y_train - ridge.predict(X_train_scaled)
plt.figure(figsize=(8, 5))
plt.scatter(ridge.predict(X_train_scaled), residuals, alpha=0.5)
plt.axhline(0, color='red', linestyle='--')
plt.title("Residuals vs Predicted SalePrice (Log)")
plt.xlabel("Predicted Log SalePrice")
plt.ylabel("Residuals")
plt.tight_layout()
plt.show()

friendly_names = {
    "TotalSF": "Total square footage (basement + 1st + 2nd floor)",
    "Age": "Years since construction (YrSold - YearBuilt)",
    "RemodAge": "Years since last remodel",
    "OverallQual": "Overall quality rating (1–10)",
    "GrLivArea": "Above ground living area (sq ft)",
    "GarageCars": "Number of cars garage can hold",
    "Fireplaces": "Number of fireplaces"
}
selected_features = list(friendly_names.keys())

print("Predict Your House Price")
print("Answer the following questions to estimate your house's value")

user_input = {}
for feature in selected_features:
    try:
        example_val = round(train[feature].median(), 2)
        prompt = feature + " (" + friendly_names[feature] + "). Example: " + str(example_val) + " → "
        val = float(input(prompt))
        user_input[feature] = val
    except:
        user_input[feature] = example_val
        print("Invalid input. Using default:", example_val)

input_df = pd.DataFrame([user_input])
input_df_full = X_train[selected_features].copy()
input_df_scaled = scaler.fit(input_df_full).transform(input_df[selected_features])
input_prediction = np.expm1(ridge.predict(input_df_scaled))[0]

print("Estimated Sale Price: $", round(input_prediction, 2))
